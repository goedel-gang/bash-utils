

function achoo { >&2 echo $@; }


declare -A ls_shorthelp
     ls_shorthelp[ls_bigold]="<depth>"
     ls_shorthelp[ls_mouldy]="<days-old> <depth>"
   ls_shorthelp[ls_size_any]="[low] [high]        # 4k 10M 2G etc"
ls_shorthelp[ls_size_suffix]="<suffix> [low]      # 4k 10M 2G etc"
ls_shorthelp[ls_file_spread]="# no argument"
ls_shorthelp[ls_count_files]="# no argument" 


function ls_ls {
  local f
  local help=false
  list_long="ls_bigold ls_mouldy ls_size_any ls_size_suffix ls_file_spread"
  list_short="ls_count_files"
  if [[ $1 == '-l' ]]; then
    help=true
    for f in $list_long; do
      echo -e "\n--- $f"
      $f -h
    done
    echo
  fi
  for f in $list_long; do
    printf "%-20s %s\n" "$f" "${ls_shorthelp[$f]}"
  done
  for f in $list_short; do
    printf "%-20s %s\n" "$f" "${ls_shorthelp[$f]}"
  done
  echo "---"
  echo "All these functions traverse directories. Use with care."
  echo "Use type -a funcname to see the function definition."
  if ! $help; then
    echo "Use ls_ls -l to see longer descriptions."
  fi
}


  # Nextflow specific, and even then a matter of taste.
  #
function nf_check {
if [[ -z $1 || $1 == '-h' ]]; then
cat <<DOC
  cd to a nextflow work directory specified by ticket name and tag.
  first argument: ticket name (directory in $LUSTRECELLGENI).
  second argument: work directory tag produced by Nextflow.
  Example:
  ${FUNCNAME[0]} tic-31 f2/e5ec31
DOC
return 1
fi
  local ticket=$1
  local tag=$2
  cd $LUSTRECELLGENI/$ticket/work/$tag*
}


function ls_bigold {
if [[ -z $1 || $1 == '-h' ]]; then
cat <<DOC
  List directories up to a certain depth, ordered by disk usage,
  with the number of days since last modified.
  Argument: directory depth.
  Example:
  ${FUNCNAME[0]} 2
  NOTE: in a project/team root directory this may take some time and
  tax the file system. Perhaps best to save the output in a file.
  CAVEAT subdirectories of a directory may have changed. Use as guide!
  USEFUL order the output by the third column to group directories together,
    e.g. ls_bigold 2 > out.bigold; sort -k 3 out.bigold
DOC
return 1
fi
  local depth=$1
  (   # do not export in user shell.
  export now=$(date +%s)
  du -h -d $depth --time --time-style=+%s |\
  perl -ane '$F[1]=int(($ENV{now}-$F[1])/86400); local $"="\t"; print "@F\n";' |\
  sort -h | column -t
  )
}


function ls_mouldy {
if [[ -z $1 || $1 == '-h' ]]; then
cat <<DOC
  Find directories left untouched for longer than first argument (in days)
  up to a depth of second argument.
  Example:
  ${FUNCNAME[0]} 183 3
  CAVEAT subdirectories of a directory may have changed. Use as guide!
DOC
return 1
fi
  (  # do not export in user shell.
  local staleness=${1?Need staleness as first parameter}
  local depth=${2?Need depth as second parameter}
  export now=$(date +%s)

  find -maxdepth "$depth" -type d -mtime +"$staleness" -printf "%Cs\t%p\n" |\
  perl -ane '$F[0]=int(($ENV{now}-$F[0])/86400); local $"="\t"; print "@F\n";' |\
  sort -nk 1 | column -t
  )
}


function ls_size_suffix {
if [[ -z $1 || $1 == '-h' ]]; then
cat <<DOC
  Find files ending with suffix recursively, sort by human-readable size.
  First argument: suffix, e.g. .cram or .fastq.gz
  Second (optional) argument: a lower bound for size, e.g. 10M or 64k.
  Example:
  ${FUNCNAME[0]} .fastq.gz
  ${FUNCNAME[0]} .cram 500M
  ${FUNCNAME[0]} .cram 1G
DOC
return 1
fi
  local pat=${1?Please supply a file suffix to search for, e.g. .cram or .fastq.gz}
  local low=${2:-0}
  find -name "*$pat" -size +$low -print0 | du -hc --files0-from=- | sort -h
}



function ls_size_any {
if [[ $1 == '-h' ]]; then
cat <<DOC
  List all regular files recursively and sort by human-readable size.
  First optional argument:   lower bound e.g. 10M or 16k, or 0k
  Second optional argument:  upper bound e.g. 4k (useful for small files)
  Example:
  ${FUNCNAME[0]} 10M     # find files larger than 10M
  ${FUNCNAME[0]} 0k 4k   # find small files
DOC
return 1
fi
  local low=${1:-0}
  local high=${2:+-size -$2}      # if $2 exists (:+) use the expression -size -$2.
  find -type f -size +$low $high -print0 | du -hc --files0-from=- | sort -h
}



function ls_lastfile() {
if [[ $1 == '-h' ]]; then
cat <<DOC
  Set variable lf to the last regular file that was modified.
  Optional first argument: a suffix
  Example:
  ls_lastfile .gz
DOC
return 1
fi
   local thefile=$(find  -maxdepth 1 -type f -print0 | xargs -0 \ls -rt1 | grep "$1"'$' | tail -n 1)
   if [[ -z $thefile ]]; then
      echo "not found: $1"
   elif [[ ! -f $thefile ]]; then
      echo "not a regular file: $thefile"
   else
      lf=$PWD/${thefile:2}
      echo set lf to $lf
      return 0
   fi
   lf=last-lf-request-failed
   return 1
}


  # I wonder if there are better ways of doing this. Filesystem locality probably means
  # there is nothing substantially better than using find.
  # Don't use this in a root directory or high-level directory (as it will
  # take a long time and taxes the file system); I use it
  # to check the number of files a particular piece of software creates.
  #
function ls_count_files {
  find .//. ! -name . -print | grep -c //
}


function ls_file_spread {
if [[ $1 == '-h' ]]; then
cat <<DOC
  For each directory count the number of files in it, recursively.
  The output is sorted by count, with a total tally added.
  Useful to check if applications are well-behaved and do not
  crush the file system with large numbers of files in a single directory.
  Modified from code by Glenn Jackman on stackoverflow.
DOC
return 1
fi
  local dir
  local count=0
  (
  shopt -s nullglob
  shopt -s dotglob
  while read -d '' -r dir; do
      files=("$dir"/*)
      delta=${#files[@]}
      count=$(($count+$delta))
      printf "%8d %s\n" "$delta" "$dir"
  done < <(find -type d -print0)
  printf "%8d Total sum of subcounts\n" "$count"
  ) | sort -n
}


  # TODO: check and all do not mix currently. add -h.
  #
function colcount()
{ local check=false
  local all=false
  local ret=0
  if [[ ! -z "$1" ]] && [[ $1 == -c ]]; then
    check=true
    shift
  elif [[ ! -z "$1" ]] && [[ $1 == -a ]]; then
    all=true
    shift
  fi
  if [[ -z "$1" ]]; then
    achoo "Need file name argument"
    return 1
  fi

  if $all; then
    perl -ne '$n=tr/\t/\t/+1;print"$n\n"' $1 | sort | uniq -c | sort -n | perl -pe 's/^\s+(\d+)\s+(\d+)/$2\t$1/'
  else
    c1=$(head -n 1 $1 | tr '\t' '\n' | wc -l)
    c2=$(head -n 2 $1 | tail -n 1 | tr '\t' '\n' | wc -l)
    c3=$(head -n 3 $1 | tail -n 1 | tr '\t' '\n' | wc -l)
    if $check && ! (( $c2 == $c3 && ($c1+1 == $c2 || $c1 == $c2) )); then
      ret=1
    fi
    echo -e "$c1\t$c2\t$c3"
  fi
  return $ret
}


function colnames()
{ if [[ -z "$1" ]]; then
    achoo "Need file name argument"
    return 1
  fi
  head -n 1 $1 | tr '\t' '\n'
}


